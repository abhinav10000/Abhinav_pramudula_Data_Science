{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Endterm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJLVSQXT6zmp",
        "colab_type": "text"
      },
      "source": [
        "Mouting google drive to save and load model params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mev00NqZ2hQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a97a7c65-5ddd-4b22-e16e-c5fed4391b9e"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhZRfk6d65u1",
        "colab_type": "text"
      },
      "source": [
        "Inception Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPmkdvjm3F37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''GoogLeNet with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 conv branch\n",
        "        self.b1 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
        "            nn.BatchNorm2d(n1x1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.b2 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
        "            nn.BatchNorm2d(n3x3red),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n3x3),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.b3 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
        "            nn.BatchNorm2d(n5x5red),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n5x5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n5x5),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 3x3 pool -> 1x1 conv branch\n",
        "        self.b4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
        "            nn.BatchNorm2d(pool_planes),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.b1(x)\n",
        "        y2 = self.b2(x)\n",
        "        y3 = self.b3(x)\n",
        "        y4 = self.b4(x)\n",
        "        return torch.cat([y1,y2,y3,y4], 1)\n",
        "\n",
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        self.pre_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n",
        "        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
        "        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
        "        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
        "        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
        "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "\n",
        "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "        self.linear = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pre_layers(x)\n",
        "        out = self.a3(out)\n",
        "        out = self.b3(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.a4(out)\n",
        "        out = self.b4(out)\n",
        "        out = self.c4(out)\n",
        "        out = self.d4(out)\n",
        "        out = self.e4(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.a5(out)\n",
        "        out = self.b5(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG_ieqil7D_x",
        "colab_type": "text"
      },
      "source": [
        "Loading other necessary packages <br>\n",
        "Initializing training data, test data, model(net), criterion and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_rIvPNm3rx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f81e7372-61c9-4309-9640-fe940333220a"
      },
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pytz import timezone    \n",
        "    \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "net = GoogLeNet()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.NLLLoss()\n",
        "\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
        "#optimizer = optim.Adam(net.parameters(), lr=0.001,weight_decay=5e-4)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01NV_PWy7aey",
        "colab_type": "text"
      },
      "source": [
        "Train and Test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n3_FOdS36_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "def train():\n",
        "    \n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "  \n",
        "    print('Train Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "# Testing\n",
        "def test():\n",
        "    \n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        print('Test Loss: %.3f | Acc: %.3f%% (%d/%d)'% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZl7F1YI7dw0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0_OmDPf4Qah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "736c6f7b-d637-4b26-81aa-daa8d4a523f2"
      },
      "source": [
        "net.load_state_dict(torch.load('/content/gdrive/My Drive/DeepLearning/Inception/model_params/param_dumpy.pth')['params'])\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness = 2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "start_epoch = 25\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+0):\n",
        "  \n",
        "    sTime = time.time()\n",
        "    \n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    \n",
        "    india_time = datetime.now(timezone('Asia/Kolkata'))\n",
        "    print(india_time.strftime('%Y-%m-%d_%H-%M-%S'))\n",
        "    \n",
        "    train()\n",
        "    test()\n",
        "    \n",
        "    print('Time for this epoch:',str(time.time()-sTime))\n",
        "    \n",
        "\n",
        "params_sofar = {'params':net.state_dict(),\n",
        "               'note':'(8E SGD lr 0.1),(8E SGD lr 0.01),(8E SGD lr 0.001),(RHF CJb2 8E lr 0.01)'}\n",
        "torch.save(params_sofar, '/content/gdrive/My Drive/DeepLearning/Inception/model_params/param_dumpy.pth')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1B6FkQa6c-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4f901500-2a6e-4962-c666-832cb5395d24"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "net.eval()\n",
        "net.load_state_dict(torch.load('/content/gdrive/My Drive/DeepLearning/Inception/model_params/param_dumpy.pth')['params'])\n",
        "\n",
        "# iterate over test data\n",
        "for data, target in testloader:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = net(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(100):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(testloader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2f%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2f%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss: 0.258319\n",
            "\n",
            "Test Accuracy of plane: 95.000000% (950/1000)\n",
            "Test Accuracy of   car: 97.300000% (973/1000)\n",
            "Test Accuracy of  bird: 89.000000% (890/1000)\n",
            "Test Accuracy of   cat: 83.500000% (835/1000)\n",
            "Test Accuracy of  deer: 93.300000% (933/1000)\n",
            "Test Accuracy of   dog: 87.300000% (873/1000)\n",
            "Test Accuracy of  frog: 94.500000% (945/1000)\n",
            "Test Accuracy of horse: 94.400000% (944/1000)\n",
            "Test Accuracy of  ship: 95.300000% (953/1000)\n",
            "Test Accuracy of truck: 95.100000% (951/1000)\n",
            "\n",
            "Test Accuracy (Overall): 92.470000% (9247/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jwSKUm06w79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}